{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alphapose command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Input dir: Run AlphaPose for all images in a folder with:\n",
    "python scripts/demo_inference.py --cfg <cfg_file> --checkpoint <trained_model> --indir <img_directory> --outdir <output_directory>\n",
    "\n",
    "* Choose a different detector: Default detector is yolov3-spp, it works pretty well, if you want to use yolox series, remember to download their weight according to our installation readme. Options include [yolox-x|yolox-l|yolox-m|yolox-s|yolox-darknet]:\n",
    "python scripts/demo_inference.py --detector yolox-x --cfg <cfg_file> --checkpoint <trained_model> --indir <img_directory> --outdir <output_directory>\n",
    "\n",
    "* Video: Run AlphaPose for a video and save the rendered video with:\n",
    "python scripts/demo_inference.py --cfg <cfg_file> --checkpoint <trained_model> --video <path to video> --outdir examples/res --save_video\n",
    "\n",
    "* Webcam: Run AlphaPose using default webcam and visualize the results with:\n",
    "python scripts/demo_inference.py --cfg <cfg_file> --checkpoint <trained_model> --outdir examples/res --vis --webcam 0\n",
    "\n",
    "* Input list: Run AlphaPose for images in a list and save the rendered images with:\n",
    "python scripts/demo_inference.py --cfg <cfg_file> --checkpoint <trained_model> --list examples/list-coco-demo.txt --indir <img_directory> --outdir examples/res --save_img\n",
    "\n",
    "* Only-cpu/Multi-gpus: Run AlphaPose for images in a list by cpu only or multi gpus:\n",
    "python scripts/demo_inference.py --cfg <cfg_file> --checkpoint <trained_model> --list examples/list-coco-demo.txt --indir <img_directory> --outdir examples/res --gpus ${-1(cpu only)/0,1,2,3(multi-gpus)}\n",
    "\n",
    "* Re-ID Track(Experimental): Run AlphaPose for tracking persons in a video by human re-id algorithm:\n",
    "python scripts/demo_inference.py --cfg <cfg_file> --checkpoint <trained_model> --video <path to video> --outdir examples/res --pose_track --save_video\n",
    "\n",
    "* Simple Track(Experimental): Run AlphaPose for tracking persons in a video by MOT tracking algorithm:\n",
    "python scripts/demo_inference.py --cfg <cfg_file> --checkpoint <trained_model> --video <path to video> --outdir examples/res --detector tracker --save_video\n",
    "\n",
    "* Pose Flow(not ready): Run AlphaPose for tracking persons in a video by embedded PoseFlow algorithm:\n",
    "python scripts/demo_inference.py --cfg <cfg_file> --checkpoint <trained_model. --video <path to video> --outdir examples/res --pose_flow --save_video\n",
    "\n",
    "* Note: If you meet OOM(out of memory) problem, decreasing the pose estimation batch until the program can run on your computer:\n",
    "python scripts/demo_inference.py --cfg <cfg_file> --checkpoint <trained_model> --indir <img_directory> --outdir examples/res --detbatch 1 --posebatch 30\n",
    "\n",
    "* Getting more accurate: You can use larger input for pose network to improve performance e.g.:\n",
    "python scripts/demo_inference.py --cfg <cfg_file> --checkpoint <trained_model> --indir <img_directory> --outdir <output_directory> --flip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motionbert command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 3d pose\n",
    "python infer_wild.py \\\n",
    "--vid_path <your_video.mp4> \\\n",
    "--json_path <alphapose-results.json> \\\n",
    "--out_path <output_path>\n",
    "\n",
    "* mesh\n",
    "python infer_wild_mesh.py \\\n",
    "--vid_path <your_video.mp4> \\\n",
    "--json_path <alphapose-results.json> \\\n",
    "--out_path <output_path> \\\n",
    "--ref_3d_motion_path <3d-pose-results.npy> # Optional, use the estimated 3D motion for root trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Webcam index 0 is not available.\n",
      "Webcam index 1 is not available.\n",
      "Webcam index 2 is not available.\n",
      "Webcam index 3 is not available.\n",
      "Webcam index 4 is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@9418.283] global cap_v4l.cpp:997 open VIDEOIO(V4L2:/dev/video0): can't open camera by index\n",
      "[ERROR:0@9418.283] global obsensor_uvc_stream_channel.cpp:159 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@9418.286] global cap_v4l.cpp:997 open VIDEOIO(V4L2:/dev/video1): can't open camera by index\n",
      "[ERROR:0@9418.286] global obsensor_uvc_stream_channel.cpp:159 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@9418.288] global cap_v4l.cpp:997 open VIDEOIO(V4L2:/dev/video2): can't open camera by index\n",
      "[ERROR:0@9418.288] global obsensor_uvc_stream_channel.cpp:159 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@9418.289] global cap_v4l.cpp:997 open VIDEOIO(V4L2:/dev/video3): can't open camera by index\n",
      "[ERROR:0@9418.289] global obsensor_uvc_stream_channel.cpp:159 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@9418.291] global cap_v4l.cpp:997 open VIDEOIO(V4L2:/dev/video4): can't open camera by index\n",
      "[ERROR:0@9418.291] global obsensor_uvc_stream_channel.cpp:159 getStreamChannelGroup Camera index out of range\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "for i in range(5):\n",
    "    cap = cv2.VideoCapture(i)\n",
    "    if cap.isOpened():\n",
    "        print(f\"Webcam index {i} is available.\")\n",
    "        cap.release()\n",
    "    else:\n",
    "        print(f\"Webcam index {i} is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sjd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
