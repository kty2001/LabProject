{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from ast import literal_eval\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.patheffects as pe\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./images/baguette/0.json', 'r') as f:\n",
    "    labelme_load = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['version', 'flags', 'shapes', 'imagePath', 'imageData', 'imageHeight', 'imageWidth'])\n",
      "<class 'str'> <class 'dict'> <class 'list'> <class 'str'> <class 'str'> <class 'int'> <class 'int'>\n",
      "dict_keys(['label', 'points', 'group_id', 'description', 'shape_type', 'flags', 'mask'])\n"
     ]
    }
   ],
   "source": [
    "print(labelme_load.keys())\n",
    "print(type(labelme_load['version']), type(labelme_load['flags']), type(labelme_load['shapes']), type(labelme_load['imagePath']), type(labelme_load['imageData']), type(labelme_load['imageHeight']), type(labelme_load['imageWidth']))\n",
    "print(labelme_load['shapes'][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\images\\baguette\\0.json <class 'str'> 600\n"
     ]
    }
   ],
   "source": [
    "data_dir = \".\\\\images\"\n",
    "data = glob.glob(os.path.join(data_dir + '/*/*.json'))\n",
    "print(data[0], type(data[0]), len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_coco = {'info': {}, 'licenses': [], 'images': [], 'annotations': [], 'categories': []}\n",
    "\n",
    "for img_id in range(len(data)):\n",
    "\n",
    "    with open(data[img_id], 'r') as f:\n",
    "        load_json = json.load(f)\n",
    "\n",
    "    make_coco['images'].append({'license': 0, 'file_name': data[img_id], 'coco_url': \"\", 'height': load_json['imageHeight'], 'width': load_json['imageWidth'], 'data_captured': 0, 'flickr_url': \"\", \"id\": img_id})\n",
    "\n",
    "    for box_id, box in enumerate(load_json['shapes']):\n",
    "        category_id_list = [category['name'] for category in make_coco['categories']]\n",
    "        if box['label'] not in category_id_list:\n",
    "            make_coco['categories'].append({'supercategory': 0, 'id': len(category_id_list), 'name': box['label']})\n",
    "            category_id_list = [category['name'] for category in make_coco['categories']]\n",
    "\n",
    "        x1, y1 = min(box['points'][0][0], box['points'][1][0]), min(box['points'][0][1], box['points'][1][1])\n",
    "        x2, y2 = max(box['points'][0][0], box['points'][1][0]), max(box['points'][0][1], box['points'][1][1])\n",
    "        w, h = x2 - x1, y2 - y1\n",
    "        make_coco['annotations'].append({'segmentation': [], 'area': w * h, 'iscrowd': 0, 'image_id': img_id, 'bbox': [x1, y1, w, h], 'category_id': category_id_list.index(box['label']), 'id': box_id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['baguette', 'croissant', 'toast', 'iceamericano', 'powerade']\n",
      "----------images----------\n",
      "{'license': 0, 'file_name': '.\\\\images\\\\powerade\\\\60.json', 'coco_url': '', 'height': 168, 'width': 299, 'data_captured': 0, 'flickr_url': '', 'id': 437}\n",
      "{'license': 0, 'file_name': '.\\\\images\\\\baguette\\\\61.json', 'coco_url': '', 'height': 225, 'width': 225, 'data_captured': 0, 'flickr_url': '', 'id': 78}\n",
      "{'license': 0, 'file_name': '.\\\\images\\\\baguette\\\\98.json', 'coco_url': '', 'height': 194, 'width': 259, 'data_captured': 0, 'flickr_url': '', 'id': 118}\n",
      "----------annotations----------\n",
      "{'segmentation': [], 'area': 6402.245110386513, 'iscrowd': 0, 'image_id': 339, 'bbox': [100.7494004796163, 82.88369304556355, 68.10551558753, 94.00479616306956], 'category_id': 3, 'id': 0}\n",
      "{'segmentation': [], 'area': 37037.856952899834, 'iscrowd': 0, 'image_id': 333, 'bbox': [16.805630026809652, 10.256032171581765, 164.0750670241287, 225.7372654155496], 'category_id': 3, 'id': 0}\n",
      "{'segmentation': [], 'area': 7098.175836624482, 'iscrowd': 0, 'image_id': 396, 'bbox': [16.555710306406688, 16.555710306406688, 44.01114206128133, 161.28133704735376], 'category_id': 4, 'id': 1}\n",
      "{'segmentation': [], 'area': 2663.5477851067685, 'iscrowd': 0, 'image_id': 372, 'bbox': [7.042521994134894, 7.042521994134894, 34.0175953079179, 78.29912023460412], 'category_id': 4, 'id': 3}\n",
      "{'segmentation': [], 'area': 40394.30587049635, 'iscrowd': 0, 'image_id': 397, 'bbox': [8.52380952380953, 8.52380952380953, 105.15873015873015, 384.12698412698415], 'category_id': 4, 'id': 0}\n",
      "{'segmentation': [], 'area': 741.0507405403753, 'iscrowd': 0, 'image_id': 361, 'bbox': [111.15654952076677, 111.15654952076677, 17.571884984025573, 42.17252396166133], 'category_id': 4, 'id': 16}\n",
      "{'segmentation': [], 'area': 649.1849462585105, 'iscrowd': 0, 'image_id': 361, 'bbox': [18.82428115015975, 18.82428115015975, 16.93290734824282, 38.338658146964846], 'category_id': 4, 'id': 22}\n",
      "{'segmentation': [], 'area': 10431.768274322309, 'iscrowd': 0, 'image_id': 391, 'bbox': [7.672086720867206, 7.672086720867206, 57.452574525745256, 181.57181571815718], 'category_id': 4, 'id': 3}\n",
      "{'segmentation': [], 'area': 17072.09771750945, 'iscrowd': 0, 'image_id': 334, 'bbox': [34.562350119904075, 34.562350119904075, 97.12230215827338, 175.77937649880099], 'category_id': 3, 'id': 0}\n",
      "{'segmentation': [], 'area': 3297.057851239668, 'iscrowd': 0, 'image_id': 278, 'bbox': [27.454545454545467, 27.454545454545467, 49.81818181818181, 66.18181818181816], 'category_id': 3, 'id': 2}\n",
      "----------categories----------\n",
      "[{'supercategory': 0, 'id': 0, 'name': 'baguette'}, {'supercategory': 0, 'id': 1, 'name': 'croissant'}, {'supercategory': 0, 'id': 2, 'name': 'toast'}, {'supercategory': 0, 'id': 3, 'name': 'iceamericano'}, {'supercategory': 0, 'id': 4, 'name': 'powerade'}]\n"
     ]
    }
   ],
   "source": [
    "print(category_id_list)\n",
    "print('----------images----------')\n",
    "for i in range(3):\n",
    "    idx = random.randint(0, len(data))\n",
    "    print(make_coco['images'][idx])\n",
    "print(\"----------annotations----------\")\n",
    "for i in range(10):\n",
    "    idx = random.randint(900, 1200)\n",
    "    print(make_coco['annotations'][idx])\n",
    "print(\"----------categories----------\")\n",
    "print(make_coco['categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('make_coco.json', 'w') as make_file:\n",
    "    json.dump(make_coco, make_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['baguette', 'croissant', 'iceamericano', 'powerade', 'toast']\n",
      ".\\images\\baguette\\0.jpg\n",
      "[51, 18, 107, 106, 113, 99, 55, 53, 98, 118, 71, 115, 87, 11, 101, 41, 93, 88, 83, 72, 89, 26, 59, 68]\n"
     ]
    }
   ],
   "source": [
    "with open('labelme2coco.json', 'r') as f:\n",
    "    load_json = json.load(f)\n",
    "\n",
    "images_dir = \".\\\\images\"\n",
    "items = os.listdir(images_dir)\n",
    "subdirectories = [item for item in items if os.path.isdir(os.path.join(images_dir, item))]\n",
    "print(subdirectories)\n",
    "for subdirectory in subdirectories:\n",
    "    if subdirectory == 'croissant':\n",
    "        break\n",
    "\n",
    "    images = glob.glob(os.path.join(f\"{images_dir}\\\\{subdirectory}\\\\*.jpg\"))\n",
    "    print(images[0])\n",
    "    images_dic = {}\n",
    "\n",
    "    indices = list(range(len(images)))\n",
    "    random.shuffle(indices)\n",
    "    split_point = int(0.2 * len(images))\n",
    "\n",
    "    test_ids = indices[:split_point]\n",
    "    print(test_ids)\n",
    "    train_ids = indices[split_point:]\n",
    "\n",
    "    for test_id in test_ids:\n",
    "        for img in load_json['images']:\n",
    "            if img['file_name'] == f'.\\\\images\\\\{subdirectory}\\\\{test_id}.jpg':\n",
    "                img['license'] = 1\n",
    "\n",
    "#images_id_list = [images['file_name'] for images in load_json['images']]\n",
    "#print(images_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\images\\baguette\\0.jpg\n"
     ]
    }
   ],
   "source": [
    "images = glob.glob(os.path.join(f\".\\\\images\\\\*\\\\*.jpg\"))\n",
    "image_id = images[0]    # index에 맞는 image_id 가져오기\n",
    "print(image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = os.listdir(images_dir)\n",
    "subdirectories = [item for item in items if os.path.isdir(os.path.join(images_dir, item))]\n",
    "\n",
    "for subdirectory in subdirectories:\n",
    "\n",
    "    images = glob.glob(os.path.join(f\"{images_dir}\\\\{subdirectory}\\\\*.jpg\"))\n",
    "\n",
    "    indices = list(range(len(images)))\n",
    "    random.shuffle(indices)\n",
    "    split_point = int(0.2 * len(images))\n",
    "\n",
    "    test_ids = indices[:split_point]\n",
    "\n",
    "    for test_id in test_ids:\n",
    "        for img in load_json['images']:\n",
    "            if img['file_name'] == f'.\\\\images\\\\{subdirectory}\\\\{test_id}.jpg':\n",
    "                img['license'] = 1\n",
    "\n",
    "train_json = {}\n",
    "train_json['info'] = load_json['info']\n",
    "train_json['licenses'] = load_json['licenses']\n",
    "train_json['annotations'] = load_json['annotations']\n",
    "train_json['categories'] = load_json['categories']\n",
    "train_json['images'] = []\n",
    "test_json = {}\n",
    "test_json['info'] = load_json['info']\n",
    "test_json['licenses'] = load_json['licenses']\n",
    "test_json['annotations'] = load_json['annotations']\n",
    "test_json['categories'] = load_json['categories']\n",
    "test_json['images'] = []\n",
    "for load_json_image in load_json['images']:\n",
    "    if load_json_image['license'] == 1:\n",
    "        test_json['images'].append(load_json_image)\n",
    "    else:\n",
    "        train_json['images'].append(load_json_image)\n",
    "\n",
    "with open('train_json.json', 'w') as make_file:\n",
    "    json.dump(train_json, make_file)\n",
    "with open('test_json.json', 'w') as make_file:\n",
    "    json.dump(test_json, make_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "480\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "with open('labelme2coco.json', 'r') as f:\n",
    "    load_json = json.load(f)\n",
    "print(len(load_json['images']))\n",
    "\n",
    "with open('train_json.json', 'r') as f:\n",
    "    train_json = json.load(f)\n",
    "print(len(train_json['images']))\n",
    "\n",
    "with open('test_json.json', 'r') as f:\n",
    "    test_json = json.load(f)\n",
    "print(len(test_json['images']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanAveragePrecision:\n",
    "    def __init__(self, csv_path: os.PathLike) -> None:\n",
    "        self.id_csv2coco = {}\n",
    "        json_path = self.to_coco(csv_path)\n",
    "        self.coco_gt = COCO(json_path)\n",
    "\n",
    "        self.detections = []\n",
    "\n",
    "    def to_coco(self, csv_path: os.PathLike) -> os.PathLike:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "        grouped = df.groupby(by='image_id')\n",
    "        grouped_dict = {image_id: group for image_id, group in grouped}\n",
    "        \n",
    "        res = defaultdict(list)\n",
    "\n",
    "        n_id = 0\n",
    "        for image_id, (file_name, group) in enumerate(grouped_dict.items()):\n",
    "            res['images'].append({\n",
    "                'id': image_id,\n",
    "                'width': 1024,\n",
    "                'height': 1024,\n",
    "                'file_name': f'{file_name}.jpg',\n",
    "            })\n",
    "\n",
    "            self.id_csv2coco[file_name] = image_id\n",
    "\n",
    "            for _, row in group.iterrows():\n",
    "                x1, y1, w, h = literal_eval(row['bbox'])\n",
    "                res['annotations'].append({\n",
    "                    'id': n_id,\n",
    "                    'image_id': image_id,\n",
    "                    'category_id': 1,\n",
    "                    'area': w * h,\n",
    "                    'bbox': [x1, y1, w, h],\n",
    "                    'iscrowd': 0,\n",
    "                })\n",
    "                n_id += 1\n",
    "\n",
    "        res['categories'].extend([{'id': 1, 'name': 'wheat'}])\n",
    "            \n",
    "        root_dir = os.path.split(csv_path)[0]\n",
    "        save_path = os.path.join(root_dir, 'coco_annotations.json')\n",
    "        with open(save_path, 'w') as f:\n",
    "            json.dump(res, f)\n",
    "\n",
    "        return save_path\n",
    "    \n",
    "    def update(self, preds, image_ids):\n",
    "        for p, image_id in zip(preds, image_ids):\n",
    "            p['boxes'][:, 2] = p['boxes'][:, 2] - p['boxes'][:, 0]\n",
    "            p['boxes'][:, 3] = p['boxes'][:, 3] - p['boxes'][:, 1]\n",
    "            p['boxes'] = p['boxes'].cpu().numpy()\n",
    "\n",
    "            p['scores'] = p['scores'].cpu().numpy()\n",
    "            p['labels'] = p['labels'].cpu().numpy()\n",
    "\n",
    "            image_id = self.id_csv2coco[image_id]\n",
    "            for b, l, s in zip(*p.values()):\n",
    "                self.detections.append({\n",
    "                    'image_id': image_id,\n",
    "                    'category_id': l,\n",
    "                    'bbox': b.tolist(),\n",
    "                    'score': s\n",
    "                })\n",
    "\n",
    "    def reset(self):\n",
    "        self.detections = []\n",
    "\n",
    "    def compute(self):\n",
    "        coco_dt = self.coco_gt.loadRes(self.detections)\n",
    "\n",
    "        coco_eval = COCOeval(self.coco_gt, coco_dt, 'bbox')\n",
    "        coco_eval.evaluate()\n",
    "        coco_eval.accumulate()\n",
    "        coco_eval.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
