{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# cuda 연결 확인 코드\n",
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Webcam index 0 is not available.\n",
      "Webcam index 1 is not available.\n",
      "Webcam index 2 is not available.\n",
      "Webcam index 3 is not available.\n",
      "Webcam index 4 is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.011] global cap_v4l.cpp:997 open VIDEOIO(V4L2:/dev/video0): can't open camera by index\n",
      "[ERROR:0@0.012] global obsensor_uvc_stream_channel.cpp:159 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@0.013] global cap_v4l.cpp:997 open VIDEOIO(V4L2:/dev/video1): can't open camera by index\n",
      "[ERROR:0@0.013] global obsensor_uvc_stream_channel.cpp:159 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@0.013] global cap_v4l.cpp:997 open VIDEOIO(V4L2:/dev/video2): can't open camera by index\n",
      "[ERROR:0@0.013] global obsensor_uvc_stream_channel.cpp:159 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@0.014] global cap_v4l.cpp:997 open VIDEOIO(V4L2:/dev/video3): can't open camera by index\n",
      "[ERROR:0@0.014] global obsensor_uvc_stream_channel.cpp:159 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@0.014] global cap_v4l.cpp:997 open VIDEOIO(V4L2:/dev/video4): can't open camera by index\n",
      "[ERROR:0@0.014] global obsensor_uvc_stream_channel.cpp:159 getStreamChannelGroup Camera index out of range\n"
     ]
    }
   ],
   "source": [
    "# 카메라 연결 확인 코드\n",
    "import cv2\n",
    "\n",
    "for i in range(5):\n",
    "    cap = cv2.VideoCapture(i)\n",
    "    if cap.isOpened():\n",
    "        print(f\"Webcam index {i} is available.\")\n",
    "        cap.release()\n",
    "    else:\n",
    "        print(f\"Webcam index {i} is not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alphapose command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Input dir: Run AlphaPose for all images in a folder with:\n",
    "python scripts/demo_inference.py --cfg <cfg_file> --checkpoint <trained_model> --indir <img_directory> --outdir <output_directory>\n",
    "\n",
    "* Choose a different detector: Default detector is yolov3-spp, it works pretty well, if you want to use yolox series, remember to download their weight according to our installation readme. Options include [yolox-x|yolox-l|yolox-m|yolox-s|yolox-darknet]:\n",
    "python scripts/demo_inference.py --detector yolox-x --cfg <cfg_file> --checkpoint <trained_model> --indir <img_directory> --outdir <output_directory>\n",
    "\n",
    "* Video: Run AlphaPose for a video and save the rendered video with:\n",
    "python scripts/demo_inference.py --cfg configs/halpe_26/resnet/256x192_res50_lr1e-3_2x.yaml --checkpoint pretrained_models/halpe26_fast_res50_256x192.pth --video examples/video/cjs_exam.mp4 --outdir examples/results --save_video\n",
    "\n",
    "* Webcam: Run AlphaPose using default webcam and visualize the results with:\n",
    "python scripts/demo_inference.py --cfg <cfg_file> --checkpoint <trained_model> --outdir examples/res --vis --webcam 0\n",
    "\n",
    "* Input list: Run AlphaPose for images in a list and save the rendered images with:\n",
    "python scripts/demo_inference.py --cfg <cfg_file> --checkpoint <trained_model> --list examples/list-coco-demo.txt --indir <img_directory> --outdir examples/res --save_img\n",
    "\n",
    "* Only-cpu/Multi-gpus: Run AlphaPose for images in a list by cpu only or multi gpus:\n",
    "python scripts/demo_inference.py --cfg <cfg_file> --checkpoint <trained_model> --list examples/list-coco-demo.txt --indir <img_directory> --outdir examples/res --gpus ${-1(cpu only)/0,1,2,3(multi-gpus)}\n",
    "\n",
    "* Re-ID Track(Experimental): Run AlphaPose for tracking persons in a video by human re-id algorithm:\n",
    "python scripts/demo_inference.py --cfg <cfg_file> --checkpoint <trained_model> --video <path to video> --outdir examples/res --pose_track --save_video\n",
    "\n",
    "* Simple Track(Experimental): Run AlphaPose for tracking persons in a video by MOT tracking algorithm:\n",
    "python scripts/demo_inference.py --cfg <cfg_file> --checkpoint <trained_model> --video <path to video> --outdir examples/res --detector tracker --save_video\n",
    "\n",
    "* Pose Flow(not ready): Run AlphaPose for tracking persons in a video by embedded PoseFlow algorithm:\n",
    "python scripts/demo_inference.py --cfg <cfg_file> --checkpoint <trained_model> --video <path to video> --outdir examples/res --pose_flow --save_video\n",
    "\n",
    "* Note: If you meet OOM(out of memory) problem, decreasing the pose estimation batch until the program can run on your computer:\n",
    "python scripts/demo_inference.py --cfg <cfg_file> --checkpoint <trained_model> --indir <img_directory> --outdir examples/res --detbatch 1 --posebatch 30\n",
    "\n",
    "* Getting more accurate: You can use larger input for pose network to improve performance e.g.:\n",
    "python scripts/demo_inference.py --cfg <cfg_file> --checkpoint <trained_model> --indir <img_directory> --outdir <output_directory> --flip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data type: <class 'list'>\n",
      "data len: 145\n",
      "data[0] type: <class 'dict'>\n",
      "data[0] keys: ['image_id', 'category_id', 'keypoints', 'score', 'box', 'idx']\n",
      "data[0]['keypoints'] type: <class 'list'>\n",
      "data[0]['keypoints'] len: 78\n"
     ]
    }
   ],
   "source": [
    "# AlphaPose 결과 json 파일 내용 확인 코드\n",
    "import json\n",
    "\n",
    "file_path = 'AlphaPose/examples/results/alphapose_normal.json'\n",
    "\n",
    "with open(file_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(\"data type:\", type(data))\n",
    "print(\"data len:\", len(data))\n",
    "print(\"data[0] type:\", type(data[0]))\n",
    "print(\"data[0] keys:\", list(data[0].keys()))\n",
    "print(\"data[0]['keypoints'] type:\", type(data[0]['keypoints']))\n",
    "print(\"data[0]['keypoints'] len:\", len(data[0]['keypoints']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.jpg value------------------------------------------------------------\n",
      "Nose [0, 2] : [418.9814758300781, 102.0521469116211, 0.9640330672264099]\n",
      "LEye [3, 5] : [443.10125732421875, 89.99224853515625, 0.9506341218948364]\n",
      "REye [6, 8] : [394.8616638183594, 89.99224853515625, 0.950445294380188]\n",
      "LEar [9, 11] : [479.2809753417969, 126.17195129394531, 0.9428252577781677]\n",
      "REar [12, 14] : [358.68194580078125, 126.17195129394531, 0.9362720251083374]\n",
      "LShoulder [15, 17] : [539.5804443359375, 282.9506530761719, 0.8991542458534241]\n",
      "RShoulder [18, 20] : [310.4423522949219, 295.01055908203125, 0.9379998445510864]\n",
      "LElbow [21, 23] : [551.640380859375, 463.84918212890625, 0.9278724789619446]\n",
      "RElbow [24, 26] : [286.3225402832031, 487.9689636230469, 0.938944935798645]\n",
      "LWrist [27, 29] : [551.640380859375, 632.6878051757812, 0.9639967679977417]\n",
      "RWrist [30, 32] : [274.2626647949219, 632.6878051757812, 0.9329041242599487]\n",
      "LHip [33, 35] : [479.2809753417969, 644.7476806640625, 0.9125049114227295]\n",
      "RHip [36, 38] : [358.68194580078125, 644.7476806640625, 0.9058470726013184]\n",
      "LKnee [39, 41] : [479.2809753417969, 910.0654907226562, 0.9657179117202759]\n",
      "Rknee [42, 44] : [358.68194580078125, 910.0654907226562, 0.9404800534248352]\n",
      "LAnkle [45, 47] : [467.2210693359375, 1139.20361328125, 0.9300830960273743]\n",
      "RAnkle [48, 50] : [346.6220703125, 1139.20361328125, 0.9341339468955994]\n",
      "Head [51, 53] : [418.9814758300781, 29.69274139404297, 0.9322948455810547]\n",
      "Neck [54, 56] : [418.9814758300781, 210.59124755859375, 0.9577080011367798]\n",
      "Hip [57, 59] : [418.9814758300781, 632.6878051757812, 0.9432681798934937]\n",
      "LBigToe [60, 62] : [491.34088134765625, 1211.56298828125, 0.9457160830497742]\n",
      "RBigToe [63, 65] : [334.5621643066406, 1199.503173828125, 0.8907361030578613]\n",
      "LSmallToe [66, 68] : [515.460693359375, 1199.503173828125, 0.9610777497291565]\n",
      "RSmallToe [69, 71] : [310.4423522949219, 1187.4432373046875, 0.8932892680168152]\n",
      "LHeel [72, 74] : [455.1611633300781, 1163.323486328125, 0.8796626925468445]\n",
      "RHeel [75, 77] : [370.7418518066406, 1163.323486328125, 0.8842237591743469]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "# 26 body keypoints\n",
    "#     {0,  \"Nose\"},\n",
    "#     {1,  \"LEye\"},\n",
    "#     {2,  \"REye\"},\n",
    "#     {3,  \"LEar\"},\n",
    "#     {4,  \"REar\"},\n",
    "#     {5,  \"LShoulder\"},\n",
    "#     {6,  \"RShoulder\"},\n",
    "#     {7,  \"LElbow\"},\n",
    "#     {8,  \"RElbow\"},\n",
    "#     {9,  \"LWrist\"},\n",
    "#     {10, \"RWrist\"},\n",
    "#     {11, \"LHip\"},\n",
    "#     {12, \"RHip\"},\n",
    "#     {13, \"LKnee\"},\n",
    "#     {14, \"Rknee\"},\n",
    "#     {15, \"LAnkle\"},\n",
    "#     {16, \"RAnkle\"},\n",
    "#     {17,  \"Head\"},\n",
    "#     {18,  \"Neck\"},\n",
    "#     {19,  \"Hip\"},\n",
    "#     {20, \"LBigToe\"},\n",
    "#     {21, \"RBigToe\"},\n",
    "#     {22, \"LSmallToe\"},\n",
    "#     {23, \"RSmallToe\"},\n",
    "#     {24, \"LHeel\"},\n",
    "#     {25, \"RHeel\"},\n",
    "# x1, y1, c1, ... xk, yk, ck (c: 감지 신뢰도)\n",
    "k = ['Nose', 'LEye', 'REye', 'LEar', 'REar', 'LShoulder', 'RShoulder', 'LElbow', 'RElbow', 'LWrist', 'RWrist',\n",
    "     'LHip', 'RHip', 'LKnee', 'Rknee', 'LAnkle', 'RAnkle', 'Head', 'Neck', 'Hip', 'LBigToe', 'RBigToe', 'LSmallToe', 'RSmallToe', 'LHeel', 'RHeel']\n",
    "ex = data[10]['keypoints']\n",
    "print(\"0.jpg value------------------------------------------------------------\")\n",
    "for i in range(26*3):\n",
    "    if i % 3 == 0: print(k[i//3], [i, i+2], \":\", ex[i+0:i+3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def cal_2d_distance(x1, y1, x2, y2):\n",
    "    x = x2 - x1\n",
    "    y = y2 - y1\n",
    "    return math.sqrt(x**2 + y**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------거북목---------------\n",
      "turtle_distance: 73.14349365234375\n",
      "\n",
      "-------------골반 기울기-------------\n",
      "rad: 0.0 / abs rad: 0.0\n",
      "deg: 0.0 / abs_deg: 0.0\n",
      "\n",
      "-------------어깨 기울기-------------\n",
      "rad: -0.05258308957226969 / abs rad: 0.05258308957226969\n",
      "deg: -3.0127891062494228 / abs_deg: 3.0127891062494228\n"
     ]
    }
   ],
   "source": [
    "# 거북목 증후군 검사\n",
    "print(\"\\n---------------거북목---------------\")\n",
    "rframe = 0 # 우측면 이미지 or 프레임\n",
    "val = data[rframe]['keypoints']\n",
    "r_ear_x = val[12]\n",
    "r_shoulder_x = val[18]\n",
    "turtle_distance = r_ear_x - r_shoulder_x\n",
    "print(\"turtle_distance:\", turtle_distance)\n",
    "\n",
    "# 골반 기울기 검사\n",
    "print(\"\\n-------------골반 기울기-------------\")\n",
    "fframe = 0 # 전면 이미지 or 프레임\n",
    "val = data[fframe]['keypoints']\n",
    "l_hip = val[33:35]\n",
    "r_hip = val[36:38]\n",
    "rad = math.atan2(l_hip[1] - r_hip[1], l_hip[0] - r_hip[0])\n",
    "deg = (rad*180)/math.pi\n",
    "print(\"rad:\", rad, \"/ abs rad:\", abs(rad))\n",
    "print(\"deg:\", deg, \"/ abs_deg:\", abs(deg))\n",
    "\n",
    "# 어깨 기울기 검사\n",
    "print(\"\\n-------------어깨 기울기-------------\")\n",
    "fframe = 10 # 전면 이미지 or 프레임\n",
    "val = data[fframe]['keypoints']\n",
    "l_shoulder = val[15:17]\n",
    "r_shoulder = val[18:20]\n",
    "rad = math.atan2(l_shoulder[1] - r_shoulder[1], l_shoulder[0] - r_shoulder[0])\n",
    "deg = (rad*180)/math.pi\n",
    "print(\"rad:\", rad, \"/ abs rad:\", abs(rad))\n",
    "print(\"deg:\", deg, \"/ abs_deg:\", abs(deg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motionbert command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 3d pose\n",
    "python infer_wild.py \\\n",
    "--vid_path examples/AlphaPose_cjs_exam.mp4 \\\n",
    "--json_path examples/alphapose-results.json \\\n",
    "--out_path examples/results\n",
    "\n",
    "parser.add_argument(\"--config\", type=str, default=\"configs/pose3d/MB_ft_h36m_global_lite.yaml\", help=\"Path to the config file.\")\n",
    "parser.add_argument('-e', '--evaluate', default='checkpoint/pose3d/FT_MB_lite_MB_ft_h36m_global_lite/best_epoch.bin', type=str, metavar='FILENAME', help='checkpoint to evaluate (file name)')\n",
    "parser.add_argument('-j', '--json_path', type=str, help='alphapose detection result json path')\n",
    "parser.add_argument('-v', '--vid_path', type=str, help='video path')\n",
    "parser.add_argument('-o', '--out_path', type=str, help='output path')\n",
    "parser.add_argument('--pixel', action='store_true', help='align with pixle coordinates')\n",
    "parser.add_argument('--focus', type=int, default=None, help='target person id')\n",
    "parser.add_argument('--clip_len', type=int, default=243, help='clip length for network input')\n",
    "\n",
    "\n",
    "* mesh\n",
    "python infer_wild_mesh.py \\\n",
    "--vid_path examples/AlphaPose_cjs_exam.mp4 \\\n",
    "--json_path examples/alphapose-results.json \\\n",
    "--out_path examples/results \\\n",
    "--ref_3d_motion_path examples/results/X3D.npy(option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data type: <class 'numpy.ndarray'>\n",
      "data shape: (129, 17, 3)\n"
     ]
    }
   ],
   "source": [
    "# MotionBERT 결과 numpy 파일 내용 확인 코드\n",
    "import numpy as np\n",
    "\n",
    "file_path = 'MotionBERT/examples/results/motionbert_unnormal.npy'\n",
    "data = np.load(file_path)\n",
    "print(\"data type:\", type(data))\n",
    "print(\"data shape:\", data.shape) # (프레임 개수, 키포인트, (x,y,z) 좌표) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 frame---------------------------------------\n",
      "0 - root : [0.03768173 0.05005858 0.        ]\n",
      "1 - RHip : [-0.1000087   0.08143686  0.00129454]\n",
      "2 - RKnee : [-0.08476543  0.5595484   0.11303172]\n",
      "3 - RAnkle : [-0.09197865  0.9423065   0.23928683]\n",
      "4 - LHip : [0.16553575 0.06564985 0.03721961]\n",
      "5 - LKnee : [0.1290741  0.5565841  0.12816444]\n",
      "6 - LAnkle : [0.10348095 0.94157517 0.24331982]\n",
      "7 - torso : [ 0.014557   -0.30375177 -0.05320794]\n",
      "8 - neck : [-0.02445125 -0.645584   -0.14199507]\n",
      "9 - nose : [-0.00713882 -0.8157228  -0.26700154]\n",
      "10 - head : [-0.01392266 -0.9944185  -0.24872652]\n",
      "11 - LShoulder : [ 0.21354595 -0.6147522  -0.10536033]\n",
      "12 - LElbow : [ 0.27860343 -0.27429682  0.06236859]\n",
      "13 - LWrist : [0.27588317 0.01656048 0.07011461]\n",
      "14 - RShoulder : [-0.21510932 -0.49337065 -0.11883163]\n",
      "15 - RElbow : [-0.20651954 -0.1483562   0.03170614]\n",
      "16 - RWrist : [-0.21250343  0.14715345  0.09092017]\n"
     ]
    }
   ],
   "source": [
    "# h36m data 3d keypoints format\n",
    "# 17 3d body keypoints\n",
    "#    {0, 'root'}, \n",
    "#    {1, 'RHip'}, \n",
    "#    {2, 'RKnee'}, \n",
    "#    {3, 'RAnkle'}, \n",
    "#    {4, 'LHip'}, \n",
    "#    {5, 'LKnee'}, \n",
    "#    {6, 'LAnkle'}, \n",
    "#    {7, 'torso'}, \n",
    "#    {8, 'neck'}, \n",
    "#    {9, 'nose'}, \n",
    "#    {10, 'head'}, \n",
    "#    {11, 'LShoulder'}, \n",
    "#    {12, 'LElbow'}, \n",
    "#    {13, 'LWrist'}, \n",
    "#    {14, 'RShoulder'}, \n",
    "#    {15, 'RElbow'}, \n",
    "#    {16, 'RWrist'},\n",
    "# x, y, z\n",
    "k = ['root', 'RHip', 'RKnee', 'RAnkle', 'LHip', 'LKnee', 'LAnkle', 'torso', 'neck', 'nose', 'head', 'LShoulder', 'LElbow', 'LWrist', 'RShoulder', 'RElbow', 'RWrist']\n",
    "frame = 0\n",
    "print(frame, \"frame---------------------------------------\")\n",
    "for i, key in enumerate(data[frame]):\n",
    "    print(i, \"-\", k[i], \":\", key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def cal_2d_distance(x1, y1, x2, y2):\n",
    "    x = x2 - x1\n",
    "    y = y2 - y1\n",
    "    return math.sqrt(x**2 + y**2)\n",
    "\n",
    "def cal_3d_distance(p1, p2):\n",
    "    x1, y1, z1 = p1\n",
    "    x2, y2, z2 = p2\n",
    "    \n",
    "    x = x2 - x1\n",
    "    y = y2 - y1\n",
    "    z = z2 - z1\n",
    "    return math.sqrt(x**2 + y**2 + z**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------거북목---------------\n",
      "rad: -1.2737014458393237 / abs rad: 1.2737014458393237\n",
      "deg: -72.97771720630405 / abs_deg: 72.97771720630405\n",
      "\n",
      "-------------골반 기울기-------------\n",
      "rad: -0.05884672846882429 / abs rad: 0.05884672846882429\n",
      "deg: -3.371669179415981 / abs_deg: 3.371669179415981\n",
      "\n",
      "-------------어깨 기울기-------------\n",
      "rad: -0.27983190933826185 / abs rad: 0.27983190933826185\n",
      "deg: -16.03318737816989 / abs_deg: 16.03318737816989\n"
     ]
    }
   ],
   "source": [
    "# 거북목 증후군 검사\n",
    "print(\"\\n---------------거북목---------------\")\n",
    "frame = 10 # 우측면 이미지 or 프레임\n",
    "val = data[frame]\n",
    "head = val[10]\n",
    "neck = val[8]\n",
    "tutle_xz = cal_2d_distance(head[0], head[2], neck[0], neck[2])\n",
    "rad = math.atan2(head[1] - neck[1], tutle_xz)\n",
    "deg = (rad*180)/math.pi\n",
    "print(\"rad:\", rad, \"/ abs rad:\", abs(rad))\n",
    "print(\"deg:\", deg, \"/ abs_deg:\", abs(deg))\n",
    "\n",
    "# 골반 기울기 검사\n",
    "print(\"\\n-------------골반 기울기-------------\")\n",
    "fframe = 0 # 전면 이미지 or 프레임\n",
    "val = data[fframe]\n",
    "l_hip = val[4]\n",
    "r_hip = val[1]\n",
    "hip_xz = cal_2d_distance(l_hip[0], l_hip[2], r_hip[0], r_hip[2])\n",
    "rad = math.atan2(l_hip[1] - r_hip[1], hip_xz)\n",
    "deg = (rad*180)/math.pi\n",
    "print(\"rad:\", rad, \"/ abs rad:\", abs(rad))\n",
    "print(\"deg:\", deg, \"/ abs_deg:\", abs(deg))\n",
    "\n",
    "# 어깨 기울기 검사\n",
    "print(\"\\n-------------어깨 기울기-------------\")\n",
    "fframe = 10 # 전면 이미지 or 프레임\n",
    "val = data[fframe]\n",
    "l_shoulder = val[11]\n",
    "r_shoulder = val[14]\n",
    "shoulder_xz = cal_2d_distance(l_shoulder[0], l_shoulder[2], r_shoulder[0], r_shoulder[2])\n",
    "rad = math.atan2(l_shoulder[1] - r_shoulder[1], shoulder_xz)\n",
    "deg = (rad*180)/math.pi\n",
    "print(\"rad:\", rad, \"/ abs rad:\", abs(rad))\n",
    "print(\"deg:\", deg, \"/ abs_deg:\", abs(deg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold: 25\n",
      "(129, 17, 3)\n",
      "middle_data\n",
      "(79, 17, 3)\n",
      "mean_data\n",
      "(17, 3)\n"
     ]
    }
   ],
   "source": [
    "copyed_data = data.copy()\n",
    "data_len = len(copyed_data)\n",
    "threshold = int(data_len * 0.2)\n",
    "print(\"threshold:\", threshold)\n",
    "print(copyed_data.shape)\n",
    "middle_data = copyed_data[threshold:data_len-threshold]\n",
    "print(\"middle_data\")\n",
    "print(middle_data.shape)\n",
    "mean_data = np.mean(middle_data, axis=0)\n",
    "print(\"mean_data\")\n",
    "print(mean_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------거북목---------------\n",
      "rad: -1.2474560551035576 / abs rad: 1.2474560551035576\n",
      "deg: -71.4739670854729 / abs_deg: 71.4739670854729\n",
      "\n",
      "-------------골반 기울기-------------\n",
      "rad: -0.04866046800162735 / abs rad: 0.04866046800162735\n",
      "deg: -2.7880394456246385 / abs_deg: 2.7880394456246385\n",
      "\n",
      "-------------어깨 기울기-------------\n",
      "rad: -0.26929184342668594 / abs rad: 0.26929184342668594\n",
      "deg: -15.429286085646885 / abs_deg: 15.429286085646885\n"
     ]
    }
   ],
   "source": [
    "# 거북목 증후군 검사\n",
    "print(\"\\n---------------거북목---------------\")\n",
    "head = mean_data[10]\n",
    "neck = mean_data[8]\n",
    "tutle_xz = cal_2d_distance(head[0], head[2], neck[0], neck[2])\n",
    "rad = math.atan2(head[1] - neck[1], tutle_xz)\n",
    "deg = (rad*180)/math.pi\n",
    "print(\"rad:\", rad, \"/ abs rad:\", abs(rad))\n",
    "print(\"deg:\", deg, \"/ abs_deg:\", abs(deg))\n",
    "\n",
    "# 골반 기울기 검사\n",
    "print(\"\\n-------------골반 기울기-------------\")\n",
    "l_hip = mean_data[4]\n",
    "r_hip = mean_data[1]\n",
    "hip_xz = cal_2d_distance(l_hip[0], l_hip[2], r_hip[0], r_hip[2])\n",
    "rad = math.atan2(l_hip[1] - r_hip[1], hip_xz)\n",
    "deg = (rad*180)/math.pi\n",
    "print(\"rad:\", rad, \"/ abs rad:\", abs(rad))\n",
    "print(\"deg:\", deg, \"/ abs_deg:\", abs(deg))\n",
    "\n",
    "# 어깨 기울기 검사\n",
    "print(\"\\n-------------어깨 기울기-------------\")\n",
    "l_shoulder = mean_data[11]\n",
    "r_shoulder = mean_data[14]\n",
    "shoulder_xz = cal_2d_distance(l_shoulder[0], l_shoulder[2], r_shoulder[0], r_shoulder[2])\n",
    "rad = math.atan2(l_shoulder[1] - r_shoulder[1], shoulder_xz)\n",
    "deg = (rad*180)/math.pi\n",
    "print(\"rad:\", rad, \"/ abs rad:\", abs(rad))\n",
    "print(\"deg:\", deg, \"/ abs_deg:\", abs(deg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sjd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
